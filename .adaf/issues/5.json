{
  "id": 5,
  "title": "Broadcast backpressure deadlock stalls entire daemon when TUI client stops reading",
  "description": "## Summary\n\nWhen a TUI client stops reading from the Unix domain socket (e.g. user switches away from terminal, SSH congestion), the broadcast() function in session/daemon.go blocks on cc.flush() -\u003e net.Conn.Write() because there is no write deadline set on client connections. This creates a backpressure chain that deadlocks the entire event pipeline.\n\n## Chain of events\n\n1. broadcast() at daemon.go:492-522 writes to ALL connected clients synchronously\n2. cc.flush() calls net.Conn.Write() with NO write deadline\n3. If client stops reading, socket buffer fills, flush() blocks\n4. The forwarding goroutine stalls (stuck in broadcast())\n5. o.eventCh (cap 256) accumulates events from all senders\n6. When eventCh reaches capacity, ALL senders block:\n   - Spawn bridge goroutines\n   - pollSpawnStatus goroutine\n   - OnEnd/OnStart/OnPrompt callbacks in loops\n7. Spawn goroutines hang at l.OnEnd() in loop.go:458\n8. l.Run() never returns for the spawn\n9. Parent's waitForAnySessionSpawns polls forever seeing spawn as still running\n\n## Observed impact\n\nIn session 85b28d88 (aworld project, plan v1-1):\n- Codex spawn #4: agent finished at 13:14:36, spawn loop reported completion at 13:41:25 — 26m49s gap\n- Codex spawn #12: agent finished at 14:09:29, spawn loop reported completion at 15:30:35 — 1h21m6s gap\n- During gaps, ZERO log output from ANY goroutine in the entire daemon process\n- Only codex spawns affected because they're slowest (4-7min), finish last, user has stepped away\n\n## Why only codex\n\nCodex runs are the slowest (4-7 minutes). By the time they finish, they're the last remaining spawn. The user has likely switched terminals. Gemini/devstral2 complete in 30s-2min before the client becomes unresponsive. Spawn #7 (also codex, no gap) completed during an active period with other spawns running.\n\n## Suggested fixes (in order of robustness)\n\n1. **Per-client buffered writer goroutine**: Each client gets its own goroutine + buffered channel. broadcast() sends non-blocking to per-client channels. Slow clients get disconnected after buffer overflow. This eliminates the fundamental design issue.\n\n2. **Write deadlines on client sockets**: In broadcast(), set `cc.conn.SetWriteDeadline(time.Now().Add(5*time.Second))`. If write times out, disconnect the slow client.\n\n3. **Non-blocking OnEnd channel send**: Use select with timeout in orchestrator.go OnEnd callback:\n   ```go\n   select {\n   case o.eventCh \u003c- msg:\n   case \u003c-time.After(5 * time.Second):\n       debug.LogKV(\"orch\", \"OnEnd eventCh send timed out\")\n   }\n   ```\n\n## Files involved\n\n- internal/session/daemon.go: broadcast(), writeLine(), flush() — no write deadline\n- internal/orchestrator/orchestrator.go: OnEnd callback at ~line 544-552 — blocking eventCh send\n- internal/loop/loop.go:458 — OnEnd call site that blocks the spawn goroutine\n- internal/looprun/runner.go:762-787 — waitForAnySessionSpawns silent polling",
  "status": "open",
  "priority": "critical",
  "labels": [
    "bug",
    "daemon",
    "orchestrator",
    "tui"
  ],
  "created": "2026-02-13T16:29:09.821566279Z",
  "updated": "2026-02-13T16:29:09.821566279Z"
}