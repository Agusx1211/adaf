{
  "updated": "2026-02-12T03:28:11.23088544Z",
  "agents": {
    "claude": {
      "name": "claude",
      "path": "/home/agusx1211/.bun/install/global/node_modules/@anthropic-ai/claude-code/cli.js",
      "version": "2.1.34",
      "capabilities": [
        "prompt-arg",
        "model-select",
        "auto-approve",
        "stream-output"
      ],
      "supported_models": [
        "opus",
        "haiku",
        "sonnet",
        "claude-sonnet-4",
        "claude-haiku-4-5",
        "claude-opus-4-1",
        "claude-opus-4",
        "claude-sonnet-4-5",
        "claude-sonnet-4-5-20250929",
        "claude-haiku-4",
        "claude-opus-4-5",
        "claude-opus-4-6",
        "claude-haiku-4-5-20251001",
        "claude-sonnet-4-20250514",
        "claude-opus-4-20250514",
        "claude-opus-4-1-20250805",
        "claude-opus-4-5-20251101",
        "claude-opus-4-0"
      ],
      "reasoning_levels": [
        {
          "name": "low"
        },
        {
          "name": "medium"
        },
        {
          "name": "high"
        },
        {
          "name": "max"
        }
      ],
      "default_model": "sonnet",
      "detected": true,
      "detected_at": "2026-02-12T03:28:11.230871274Z"
    },
    "codex": {
      "name": "codex",
      "path": "/home/agusx1211/.bun/install/global/node_modules/@openai/codex/bin/codex.js",
      "version": "0.98.0",
      "capabilities": [
        "prompt-arg",
        "model-select",
        "auto-approve",
        "tty-required"
      ],
      "supported_models": [
        "gpt-5.3-codex",
        "gpt-5.2-codex",
        "gpt-5.1-codex-max",
        "gpt-5.2",
        "gpt-5.1-codex-mini"
      ],
      "reasoning_levels": [
        {
          "name": "low"
        },
        {
          "name": "medium"
        },
        {
          "name": "high"
        },
        {
          "name": "xhigh"
        }
      ],
      "default_model": "o4-mini",
      "detected": true,
      "detected_at": "2026-02-12T03:28:11.230871274Z"
    },
    "gemini": {
      "name": "gemini",
      "path": "/home/agusx1211/.nvm/versions/node/v22.3.0/lib/node_modules/@google/gemini-cli/dist/index.js",
      "version": "unknown",
      "capabilities": [
        "prompt-arg",
        "model-select",
        "auto-approve",
        "stream-output"
      ],
      "supported_models": [
        "gemini-2.5-pro",
        "gemini-2.5-flash",
        "gemini-2.0-flash"
      ],
      "default_model": "gemini-2.5-pro",
      "detected": true,
      "detected_at": "2026-02-12T03:28:11.230871274Z"
    },
    "goose": {
      "name": "goose",
      "path": "/home/agusx1211/.local/bin/goose",
      "version": "1.0.15",
      "capabilities": [
        "stdin-prompt",
        "stream-output"
      ],
      "detected": true,
      "detected_at": "2026-02-12T03:28:11.230871274Z"
    },
    "opencode": {
      "name": "opencode",
      "path": "/home/agusx1211/.nvm/versions/node/v22.3.0/lib/node_modules/opencode-ai/bin/opencode",
      "version": "1.1.59",
      "capabilities": [
        "stdin-prompt",
        "model-select",
        "multi-provider",
        "stream-output"
      ],
      "supported_models": [
        "lmstudio/qwen3-vl-2b-instruct",
        "lmstudio/qwen/qwen3-vl-8b",
        "lmstudio/openai/gpt-oss-120b",
        "lmstudio/qwen/qwen3-vl-4b",
        "lmstudio/google/gemma-3n-e4b",
        "lmstudio/text-embedding-nomic-embed-text-v1.5",
        "lmstudio/thedrummer_behemoth-r1-123b-v2",
        "lmstudio/wan2.1-t2v-14b",
        "lmstudio/gpt-oss-120b-derestricted",
        "lmstudio/gpt-oss-120b-derestricted_moe",
        "lmstudio/qwen3-vl-235b-a22b-thinking",
        "lmstudio/qwen/qwen3-vl-30b",
        "lmstudio/devstral-2-123b-instruct-2512",
        "lmstudio/qwen3-vl-2b-thinking"
      ],
      "default_model": "openai/gpt-4.1",
      "detected": true,
      "detected_at": "2026-02-12T03:28:11.230871274Z"
    },
    "vibe": {
      "name": "vibe",
      "path": "/home/agusx1211/.local/share/uv/tools/mistral-vibe/bin/vibe",
      "version": "1.3.5",
      "capabilities": [
        "stdin-prompt",
        "stream-output"
      ],
      "supported_models": [
        "devstral-2",
        "devstral-small",
        "local",
        "gpt-oss-120b",
        "local-devstral2",
        "qwen-coder-next"
      ],
      "default_model": "default",
      "detected": true,
      "detected_at": "2026-02-12T03:28:11.230871274Z"
    }
  }
}